\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{amsthm}

\usepackage{amsthm,amsmath,amsfonts,amssymb,amstext,enumitem}
\usepackage{latexsym,ifthen,url,rotating,graphicx}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{arrows,shapes,positioning,fit}
\usepackage{graphicx}
\usepackage[font=small,labelfont=bf]{caption}



% --- -----------------------------------------------------------------
% --- Document-specific definitions.
% --- -----------------------------------------------------------------
\lstset{
    columns=fixed,
    literate={—}{{---}}1 {…}{{...}}1
}

\newcommand{\todo}[1]{{\color{red}[TODO:{#1}]}}

\newtheorem{problem}{Problem}
\newtheorem{corollary}{Corollary}
\newtheorem{fact}{Fact}
\newtheorem{exercise}{Exercise}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{notation}{Notation}
\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}

\newcommand{\getsr}
  {{\:\stackrel{\raisebox{-2pt}{${\scriptscriptstyle \hspace{0.2em}\$}$}}
   {\leftarrow}\:}}
\newcommand{\points}[1]{\textbf{({#1} pts)}}

\newcommand{\fn}{\footnotesize}
\newcommand{\Colon}{\ : \ }
\newcommand{\st}{\mathsf{state}}
\newcommand{\msgs}{\mathcal{M}}
\newcommand{\ctxts}{\mathcal{C}}
\newcommand{\keys}{\mathcal{K}}
\newcommand{\rands}{\mathcal{R}}
\newcommand{\states}{\mathcal{S}}
\newcommand{\kg}{\mathcal{K}}
\newcommand{\Enc}{\mathsf{Enc}}
\newcommand{\Dec}{\mathsf{Dec}}
\newcommand{\MAC}{\mathrm{MAC}}
\newcommand{\RMAC}{\mathrm{RMAC}}

\newcommand{\pk}{pk}
\newcommand{\sk}{sk}

\newcommand{\calD}{\mathcal{D}}
\newcommand{\calA}{\mathcal{A}}
\newcommand{\calB}{\mathcal{B}}
\newcommand{\AES}{\mathsf{AES}}

\newcommand{\algorithm}[1]{\textbf{Alg} {#1}}

\newcommand{\calO}{\mathcal{O}}

\newcommand{\dlog}{\mathrm{dlog}}

\newcommand{\Adv}{\mathbf{Adv}}
\newcommand{\AdvPRF}[2]{\Adv^{\mathrm{prf}}_{#1}({#2})}
\newcommand{\AdvPRG}[2]{\Adv^{\mathrm{prg}}_{#1}({#2})}
\newcommand{\AdvCPA}[2]{\Adv^{\mathrm{ind{-}cpa}}_{#1}({#2})}
\newcommand{\AdvCCA}[2]{\Adv^{\mathrm{ind{-}cca}}_{#1}({#2})}
\newcommand{\AdvKR}[2]{\Adv^{\mathrm{kr}}_{#1}({#2})}
\newcommand{\AdvCKR}[2]{\Adv^{\mathrm{ckr}}_{#1}({#2})}
\newcommand{\AdvRMR}[2]{\Adv^{\mathrm{rmr}}_{#1}({#2})}
\newcommand{\AdvCR}[2]{\Adv^{\mathrm{cr}}_{#1}({#2})}
\newcommand{\AdvUFCMA}[2]{\Adv^{\textrm{uf{-}cma}}_{#1}({#2})}
\newcommand{\AdvDL}[2]{\Adv^{\mathrm{dl}}_{#1}({#2})}

\newcommand{\Exp}{\mathbf{Exp}}
\newcommand{\ExpOW}[1]{\Exp^{\mathrm{ow}}({#1})}
\newcommand{\ExpCKR}[2]{\Exp^{\mathrm{ckr}}_{#1}({#2})}
\newcommand{\ExpRMR}[2]{\Exp^{\mathrm{rmr}}_{#1}({#2})}

\newcommand{\concat}{{\,\|\,}}
\newcommand{\xor}{\oplus}
\newcommand{\bits}{\{0,1\}}

\newcommand{\tcolh}{T^{\mathrm{col}}_h}
\newcommand{\tcolH}{T^{\mathrm{col}}_{H^2}}
\newcommand{\Hcomb}{H^{1\|2}}
\newcommand{\Hxor}{H^{1\oplus2}}

\newcommand{\EXP}{\textrm{EXP}}
\newcommand{\MODEXP}{\textrm{MOD{-}EXP}}
\newcommand{\ADD}{\textrm{ADD}}
\newcommand{\MULTIMODEXP}{\textrm{MULTI{-}MOD{-}EXP}}
\newcommand{\MUL}{\textrm{MUL}}
\newcommand{\MOD}{\textrm{MOD}}

\newcommand{\GG}{\mathbb{G}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\bK}{\mathbf{K}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\bC}{\mathbf{C}}

\newcommand{\rvrange}{\mathcal{R}}
\newcommand{\rspace}{\mathcal{C}}

\newcommand{\hatalpha}{\hat{\alpha}}
\newcommand{\hatb}{\hat{b}}

\newcommand{\barm}{\overline{m}}

\newcommand{\otp}{\mathrm{OTP}}
\newcommand{\des}{\mathrm{DES}}
\newcommand{\twodes}{\mathrm{2DES}}
\newcommand{\threedes}{\mathrm{3DES}}
\newcommand{\threedestwo}{\mathrm{3DES2}}
\newcommand{\aes}{\mathrm{AES}}
\newcommand{\pad}{\mathsf{pad}}
\newcommand{\unpad}{\mathsf{unpad}}


\newcommand{\Img}{\mathrm{Im}}

\newcommand{\Expt}{\mathbf{Expt}}
\newcommand{\ExptOTCPA}{\mathbf{Expt}^{\mathrm{ot\mbox{-}cpa}}}
\newcommand{\ExptOTCPAone}{\mathbf{Expt}^{\mathrm{ot\mbox{-}cpa\mbox{-}1}}}
\newcommand{\ExptOTCPAzero}{\mathbf{Expt}^{\mathrm{ot\mbox{-}cpa\mbox{-}0}}}
\newcommand{\AdvOTCPA}[2]{\Adv^{\mathrm{ot\mbox{-}cpa}}_{#1}({#2})}
\newcommand{\ExptCPAone}{\mathbf{Expt}^{\mathrm{cpa\mbox{-}1}}}
\newcommand{\ExptCPAzero}{\mathbf{Expt}^{\mathrm{cpa\mbox{-}0}}}

\newcommand{\Piotp}{\Pi_\mathrm{otp}}
\newcommand{\Encotp}{\Enc_\mathrm{otp}}
\newcommand{\Decotp}{\Dec_\mathrm{otp}}
\newcommand{\bhat}{\hat{b}}
% --- -----------------------------------------------------------------
% --- Lecture notes formatting macros
% --- -----------------------------------------------------------------

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
%\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theexercise}{\thelecnum.\arabic{exercise}}
\renewcommand{\theexample}{\thelecnum.\arabic{example}}
\renewcommand{\thedefinition}{\thelecnum.\arabic{definition}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thefact}{\thelecnum.\arabic{fact}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}


%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[2]{
   %\pagestyle{myheadings}
   %\thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf CMSC 28400 Introduction to Cryptography
                        \hfill Autumn 2020} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill #2 \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Instructor: David Cash} \hfill }
      \vspace{2mm}}
   }
   \end{center}
   %\markboth{Lecture #1: #2}{Lecture #1: #2}
   \vspace*{4mm}
}





% --- -----------------------------------------------------------------
% --- The document starts here.
% --- -----------------------------------------------------------------
\begin{document}
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{5}{Notes \#5: One-Time Chosen-Plaintext Security of Ciphers}

So far we've studied stream ciphers, and briefly looked at block ciphers.
We previously discussed the pseudo-OTP, and how it can be built with any
stream cipher. In future notes we'll look at how to build ciphers for large
messages from block ciphers as well.

For these notes, we return to the pseudo-OTP, and ask: When is it
\emph{secure}? The answer to this question is, in some strong sense:
``Whenever $G$ is a good pseudorandom generator''. Formalizing first the
question and then the solution is our goal here. 

\section{Analyzing the Security of a Cipher}

%Are any of the constructions from the last section \emph{secure}? If so, can we
%say that some are \emph{more secure} than others? 

%The old approach to answering these sorts of questions, dating back to the
%birth of cryptography, is to think about how the constructions might be used
%and to look for attacks. In practice this approach is effective for some types
%of problems, and is still important today; In future sets of notes we'll look
%at encryption security from that point of view.

Since about the 1980's, an approach for thinking about security has been
developed that extends Shannon's idea of giving \emph{mathematical definitions}
of security. For better or worse, this approach is called ``provable
security.'' We have seen a bit of this already in our analysis of stream
ciphers, when we used a definition of pseudorandom generator distinguishing
advantage.

At a high level, the provable security approach works in three distinct steps:
(1) Defining security goals, (2) Defining computational assumptions, and (3)
Proving security via reductions.  Each of these steps involves idiosyncrasies
that will be discussed in turn.


\subsection{Defining Security Goals}

The first step is finding a definition of ``security'' that enumerates what an
adversary is allowed to do and how much computational effort it my expend.  In
this step we seek to formalize something like 
{\quote{ \emph{``We should prevent an adversary mounting a chosen-plaintext
attack, and employ any algorithmic strategy in $2^{100}$ time, from learning
any non-trivial information about plaintexts it does not already know.''} }}
\smallskip

The salient features of this informal definition include the adversary
capabilities (chosen-plaintext attack), a resource bound ($2^{100}$ time), and
a goal (learning information about plaintexts that it does not already know).
Also central to this approach is that we want to allow \emph{any} algorithmic
strategy, including ones we don't know about ourselves. This is remarkable
because the current state of theoretical computer science is not very good at
reasoning about the limits of general time-bounded algorithms. This situation
is very similar to that of pseudorandom generators, where we wanted to think
only of time-bounded distinguishers failing, but we have no real tools for
proving anything conclusive about them.

\section{One-Time Chosen-Plaintext Security of a Cipher}

With that said, let's just run through a definition and interpret it later.  
In this definition, the symbol $\calA$ refers to an ``algorithm'', which we
think of informally; It's an entity that can be ``run'', with or without
input. It has some internal persistent memory, and the next time it is run
it will ``remember'' everything it has seen.

The definition uses the notation $x\getsr X$ to mean ``select a random
sample from the set $X$, and call it $x$.''
\begin{definition}
    Let $E:\keys\times\msgs\to\ctxts$ be a cipher.  
    Assume that the message-space $\msgs$ is a set of bit strings, 
    i.e.
    $\msgs\subseteq\bits^*$.
    Let $\calA$
    be an algorithm. Define algorithm $\ExptOTCPA_E(\calA)$ as
    \begin{center}
    \begin{tabular}{c}
        \begin{minipage}{2in}\begin{tabbing}
            123\=123\=\kill
            \underline{\algorithm{$\ExptOTCPA_E(\calA)$}} \\[2pt]
            \fn01 \> Run $\calA$, which produces $(m_0,m_1)\in\msgs$\\
            \fn02 \> If $m_0$ and $m_1$ are different lengths: Output $0$\\
            \fn03 \> Pick $k\getsr \keys, b\getsr \bits$\\
            \fn 04 \> Compute $c \gets E(k,m_b)$ and run $\calA(c)$, which
            produces $\hatb\in\bits$\\
            \fn05\> If $\hatb = b$: Output 1\\
            \fn06 \> Else: Output 0
        \end{tabbing}\end{minipage}
    \end{tabular}
    \end{center}
    Define the \emph{one-time CPA advantage of $\calA$ against $E$} as
    \[
        \AdvOTCPA{E}{\calA} =
        \left|\Pr[\ExptOTCPA_E(\calA) = 1] - \frac{1}{2}\right|.
    \]
\end{definition}
The algorithm $\ExptOTCPA_E(\calA)$ should be thought of as a
``test-harness'' for $\calA$. This algorithm is not something we would ever
use in practice, as it does not nothing useful other than evaluate a
potential adversary $\calA$. As with pseudorandom generators,
the advantage $\AdvOTCPA{E}{\calA}$ is a ``score'', this time between $0$ and
$1/2$; The higher the advantage, the better the adversary.

Most of the complexity in this definition is in $\ExptOTCPA_E(\calA)$.
Intuitively, the experiment has $\calA$ declare two messages that it would like
to be challenged on. If $\calA$ chooses messages of different lengths, then it
automatically loses (because the experiment outputs $0$, which means the
adversary has lost). Otherwise, the experiment picks a random key and a bit
$b$, and encrypts $m_b$ under the chosen key and hands the ciphertext back to
the adversary. The adversary then outputs its guess $\hatb$: Intuitively 
$\hatb$ indicates which
message it thinks was more likely to be encrypted. If correct, the experiment
indicates a win by outputting $1$, and otherwise it indicates a loss with $0$.

Note that even a very simple $\calA$ can win with probability $1/2$, say by
always outputting $1$ or always $0$. The goal of the adversary is to do better
than that, so the definition subtracts $1/2$ (if we didn't do this, we could
just mentally calibrate our expectations, but this is simpler). In practice, an adversary running in time (say) $2^{100}$ and
achieving $\AdvOTCPA{E}{\calA} = 1/2^{100}$ may be considered a ``break,''
depending on the exact parameters like key-length.


Let's try to get some intuition for this definition. We previously saw
that most classical ciphers were not perfectly secret. Most are also not
secure under this definition, in the sense that there exists an efficient
adversary $\calA$ with high advantage. The next example shows this for
a bit-wise version of the Vigenere cipher.
\begin{example}
    Let $E:\keys\times\msgs\to\ctxts$ be a cipher with 
    $\keys = \bits^n$ and
    $\msgs = \ctxts = \bits^{2n}$ defined as follows. For a message
    $m = m[1]\|m[2]$ where $m[1],m[2]\in\bits^n$ and a key $k\in\bits^n$,
    \[
        E(k,m) = (k\oplus m[1])\|(k\oplus m[2]).
    \]
    We give an efficient
    $\calA$ such that $\AdvOTCPA{E}{\calA} = 1/2$.  Before giving the code,
    let's note what syntax our $\calA$ should have: It should start by
    outputting a pair of messages $(m_0,m_1)$ to the experiment. Then it should take
    as input a ciphertext $c$ from the experiment, and then emit a bit $\bhat$ that
    is a good guess for the hidden bit $b$.  In
    order to avoid losing automatically, $m_0$ and $m_1$ should be the same
    length, but this is forced upon us by the message space, where all messages
    are length $2n$. 

    Our adversary $\calA$ works as follows:
    \begin{center}
    \begin{tabular}{c}
        \begin{minipage}{2in}\begin{tabbing}
            123\=123\=\kill
            \underline{Adversary $\calA$} \\[2pt]
            \fn01 \> Output $m_0 = 0^{n}\|0^{n}, m_1=0^{n}\|1^{128}$.\\
            \fn02 \> Upon receiving $c$, parse $c[1]\|c[2]\gets c$, where
            $c[1],c[2]\in\bits^{n}$ \\
            \fn03 \> If $c[1]=c[2]$: Output $\bhat=0$\\
            \fn04 \> Else: Output $\bhat=1$.
        \end{tabbing}\end{minipage}
    \end{tabular}
    \end{center}
    We show that $\Pr[\ExptOTCPA_E(\calA) = 1]=1$. If $b=0$, then the message
    $m_0=0^{128}\|0^{128}$ will be encrypted, and we will have that $c=k\|k$.
    Hence $c[1]=c[2]$ and $\calA$ will output $\bhat=0$.  If $b=1$ then we'll
    get that $\calA$ outputs $\bhat=1$ instead, because $c[1]=k\neq k\oplus 1^n
    =c[2]$.  Thus $\bhat=b$ with probability $1$.
\end{example}
The one-time-CPA definition is strong is some senses.  For instance, the
definition implies, roughly speaking, that if an adversary could compute
\emph{any} non-trivial information about the message inside of a ciphertext,
then it can also win the experiment. The next example formalizes this. This example
is also our first instance of a ``reduction'', a technique that we will discuss
more thoroughly later.
\begin{example}
    Let $E:\keys\times\msgs\to\ctxts$ be a cipher with 
    with $\msgs=\bits^{128}$.
    Suppose $\calB$ has the property that for all $k\in\keys,m\in\msgs$,
    $\calB(E(k,m))$ outputs the first bit of $m$. Consider the
    following adversary $\calA$:
    \begin{center}
    \begin{tabular}{c}
        \begin{minipage}{2in}\begin{tabbing}
            123\=123\=\kill
            \underline{Adversary $\calA$} \\[2pt]
            \fn01 \> Output $m_0 = 0^{128}, m_1=1^{128}$.\\
            \fn02 \> On input $c$, run $\calB(c)$, which outputs
            a bit $d$.\\
            \fn04 \> Output $\bhat=d$.
        \end{tabbing}\end{minipage}
    \end{tabular}
    \end{center}
    We show that $\Pr[\ExptOTCPA_E(\calA) = 1]=1$. If $b=0$, then the message
    $m_0=0^{128}$ will be encrypted, and when $\calB$ is run inside of $\calA$,
    it will output $0$. Thus $\calB$ will also output $c$ when $b=0$.  If
    $m_1=1^{128}$ then the message $m_0=1^{128}$ will be encrypted, and $\calA$
    will end up outputting $1$ for the same reason.  Putting these together,
    $\bhat=b$ with probability $1$.

    Note that the runtime of $\calA$ is very close to the runtime of $\calB$;
    the algorithm $\calA$ is just a few very efficient operations before
    and after the execution of $\calB$. Thus we can conclude that if $\calB$
    can accomplish its goal efficiently, then $\calA$ can accomplish
    its (different) goal efficiently as well.
\end{example}


In the problem set you will be asked to adapt this proof slightly for
adversaries $\calB$ computing other information, such as the number of $1$ bits
in the message. This proof strategy is hopefully intuitive-looking. It is
roughly proving ``If there exists an adversary $\calB$ accomplishing some
goal against $E$, then $E$ does not have good one-time-CPA security'' by
building the adversary $\calA$ from the adversary $\calB$. This is called
a \emph{reduction}.

Also note that the adversary $\calB$ is run \emph{inside of} adversary $\calA$
as a subroutine. It's important to understand that $\calB$ is \emph{just a
piece of code} that $\calA$ can run whenever it likes. And when $\calB$ is run,
it can't ``see'' that it is inside of $\calA$; All it can see is its input,
which is some ciphertext $c$, and it follows its code, producing the first bit
as promised.


\subsection{Relation to Perfect Secrecy}

The following theorem formalizes the relationship between one-time CPA
security and perfect secrecy.
\begin{theorem}
    Let $E:\keys\times\msgs\to\ctxts$ be a cipher with $\msgs = \bits^\ell$ for
    some integer $\ell$.  Then $E$ is perfectly secret if and only if for all
    adversaries $\calA$,
    \[
        \AdvOTCPA{E}{\calA} = 0.
    \]
\end{theorem}

We will not prove it formally, but it is important to understand this
intuitively: If all pairs of messages generate ciphertexts with the
same probability, then there is no way to win the experiment with
probability better than random guessing.

\begin{corollary}\label{cor}
    Let $\otp_\ell:\bits^\ell\times\bits^\ell\to\bits^\ell $ be the $\ell$-bit
    one-time pad encryption scheme. Then for all adversaries $\calA$,
    \[
        \AdvOTCPA{\otp_\ell}{\calA} = 0,
    \]
    and in other words
    \[
        \Pr[\ExptOTCPA_{\otp_\ell}(\calA) = 1] = \frac{1}{2}.
    \]
\end{corollary}



\section{Security of the Pseudo-One-Time-Pad}

We now return to the pseudo-one-time pad, and analyze its one-time-CPA
security.
The next theorem formalizes the intuition that if $G$ is a ``good PRG'',
then the pseudo-one-time-pad has ``good one-time-CPA security.''
Let's just state the theorem and then interpret it later.
\begin{theorem}
    Let $G : \bits^n \to \bits^\ell$. Define a cipher
    $E:\keys\times\msgs\to\ctxts$ with key-space $\keys=\bits^n$,
    message-space $\msgs=\bits^\ell$, and ciphertext-space $\ctxts=\bits^\ell$
    via
    \[
        E(k,m) = G(k)\oplus m.
    \]
    Then for every adversary $\calA$, there exists another adversary $\calD$,
    running in about the same time as $\calA$, such that
    \[
        \AdvOTCPA{E}{\calA} \leq \AdvPRG{G}{\calD}.
    \]
\end{theorem}
First look at the conclusion of the theorem: It gives an upper bound on
$\AdvOTCPA{E}{\calA}$, which means it is limiting how well $\calA$ can do
against $E$, i.e. it is concluding that $E$ has good one-time-CPA security.
This advantage is upper bounded by $\AdvPRG{G}{\calD}$, where $\calD$ is a
distinguisher running in about the same time as $\calA$.
The idea is that we transferring our belief that  $\AdvPRG{G}{\calD}$
is small to a new belief that $\AdvOTCPA{E}{\calA}$ is small.

So, for example, if $G$ is a strong modern stream cipher like Salsa20, and we
believe that for all $\calD$ running in time $2^{128}$,
$\AdvPRG{G}{\calD}<1/2^{128}$, then we can conclude that $\AdvOTCPA{\Pi}{\calA}
<1/2^{128}$ for any $\calA$ running in time $2^{128}$, which is good
one-time-cpa security for our encryption scheme.


\subsection{Security Reductions and Proof of Theorem}

In order to prove the theorem, we assume we are given some $\calA$ running in
some amount of time and achieving some one-time-CPA advantage against $E$, and
then we build the $\calD$ running in the same time against $G$. The process of
building one algorithm/adversary from another algorithm/adversary is called a
\emph{security reduction}, and is central to modern cryptography: Security
reductions relate the security properties of one object (in this case, $G$) the
security properties of another object (in this case, the cipher $E$). We stress
that we'd rather not resort to this analysis in a perfect world, and would
prefer to just
directly prove that $\AdvOTCPA{E}{\calA}$ is small. But theoretical computer
science is simply unable to prove such statements today (this is on the level
of proving $P\neq NP$, and probably much harder).

So let's do the formal proof. We must build some $\calD$ that takes as input a
string $w\in\bits^\ell$ and then outputs $0$ or $1$.  Here is the $\calD$ that
works for the proof:
\begin{center}
    \begin{tabular}{c}
        \begin{minipage}{2in}\begin{tabbing}
            123\=123\=\kill
            \underline{$\calD(w)$} \\[2pt]
            \> Run $\calA$, which produces $m_0,m_1\in\msgs$\\
            \> If $m_0,m_1$ are different lengths, output $0$\\
            \> Pick $b\getsr \bits$\\
            \> Compute $c \gets w\oplus m_b$\\
            \> Run $\calA(c)$, which produces $\hatb\in\bits$\\
            \> If $\hatb = b$: Output 1\\
            \> Else: Output 0
        \end{tabbing}\end{minipage}
    \end{tabular}
\end{center}
Here is the intuition for this distinguisher. It is trying to tell if $w$ was
drawn as an output of $G$ or as a uniformly random string. It is going to run
$\calA$, who cannot tell it is running inside of $\calD$; it's just an
algorithm that accepts inputs and provides outputs. In order to run $\calA$,
$\calD$ is going to pretend to be the one-time-CPA experiment, picking the bit
$b$ itself and checking if $\calA$ appears to be winning the
pretend-experiment.

We have designed $\calD$ so that if the input $w$ was chosen uniformly at
random, then $\calA$ has no chance at doing better than $1/2$ in the
pretend-experiment $\calD$ is running, and thus can only cause $\calD$ to
output $1$ with probability $1/2$. In this case $\calA$ is effectively
attacking the one-time pad! But if $w$ is drawn according to $G(k)$, then
$\calA$ is effectively attacking $E$, and it will tend to win. The
distinguisher observes if $\calA$ is winning or not, and then infers how $w$
must have been drawn.

In summary we have the two trains of reasoning:
\begin{align*}
    \text{$w$ is uniformly random} 
    & \implies \text{$\calA$ is attacking OTP in pretend-experiment} \\
    & \implies \text{$\calA$ can only randomly guess $b$} \\
    & \implies \text{$\calD$ outputs $1$ with probability $1/2$}.
\end{align*}
And:
\begin{align*}
    \text{$w$ is drawn according to $G(k)$} 
    & \implies \text{$\calA$ is attacking $E$ in pretend-experiment} \\
    & \implies \text{$\calA$ will guess $b$ with probability higher than $1/2$} \\
    & \implies \text{$\calD$ outputs $1$ with probability higher than $1/2$}.
\end{align*}
Together these will give the theorem.
Formally, we have the following two equations:
\[
    \Pr[\calD(\bU) = 1] = 
    \Pr[\ExptOTCPA_{\otp_\ell}(\calA) = 1] = \frac{1}{2},
\]
where the second equality holds by Corollary~\ref{cor}, and
\[
    \Pr[\calD(G(\bK)) = 1] = 
    \Pr[\ExptOTCPA_{E}(\calA) = 1].
\]
These claims are not usually justified with much calculation: A reduction
should be phrased so that they are apparent from the description. Here
is what should be checked in order to justify these equations:
\begin{itemize}

    \item The ciphertext $c$ provided to $\calA$ is drawn from the \emph{same
        distribution} as in the corresponding experiment.

    \item The output of $\calD$ should be determined in exactly the same way as
        in the corresponding experiment.

\end{itemize}
In this case, you can check that once $w$ is replaced with a random string,
then $\calD$ is computing \emph{exactly} $\ExptOTCPA_{\otp_\ell}(\calA)$,
while if $w$ is computed as $G(k)$ for a uniformly random $k$, then $\calD$
is computing \emph{exactly} $\ExptOTCPA_E(\calA)$. That is enough
to verify both equations.

The rest of the proof is just algebra:
\begin{align*}
    \AdvPRG{G}{\calD} 
    & = \left|\Pr[\calD(G(\bK)) = 1] - \Pr[\calD(\bU) = 1]\right| \\
    & = \left|\Pr[\ExptOTCPA_E(\calA) = 1]
    -  \Pr[\ExptOTCPA_{\otp_\ell}(\calA) = 1]\right| \\
    & = \left|\Pr[\ExptOTCPA_E(\calA) = 1]
    -  \frac{1}{2}\right| \\
    & = \AdvOTCPA{E}{\calA}. 
\end{align*}

\begin{exercise}
    State and prove a similar theorem for the ``inverted pseudo-one-time-pad''
    defined by
    \[
        E(k,m) = \overline{G(k)}\oplus m,
    \]
    where $\overline{G(k)}$ is the bitwise-complement of $G(k)$. What
    needs to change in $\calD$?
\end{exercise}




%\begin{theorem}
%    Let $G : \bits^n \to \bits^\ell$. Define a deterministic encryption scheme
%    $\Pi = (\Enc, \Dec)$ with key-space $\keys=\bits^n$,
%    message-space $\msgs=\bits^\ell$, and ciphertext-space $\ctxts=\bits^\ell$
%    via
%    \[
%        \Enc(k,m) = G(k)\oplus m, \quad \quad \Dec(k,c) = G(k)\oplus c.
%    \]
%    Then for every adversary $\calA$, there exists another adversary $\calD$,
%    running in about the same time as $\calA$, such that
%    \[
%        \AdvOTCPA{\Pi}{\calA} = \AdvPRG{G}{\calD}.
%    \]
%\end{theorem}
%\begin{proof}
%Build $\calD$ as follows:
%    \begin{center}
%        \begin{tabular}{c}
%            \begin{minipage}{2in}\begin{tabbing}
%                123\=123\=\kill
%                \underline{$\calD(w)$} \\[2pt]
%                \> Run $\calA$, which produces $(m_0,m_1)\in\msgs$\\
%                \> Pick $b\getsr \bits$\\
%                \> Compute $c \gets w\oplus m_b$\\
%                \> Run $\calA(c)$, which produces $\hatb\in\bits$\\
%                \> If $\hatb = b$: Output 1\\
%                \> Else: Output 0
%            \end{tabbing}\end{minipage}
%        \end{tabular}
%    \end{center}
%    \[
%        \Pr[\calD(G(\bK)) = 1] = 
%        \Pr[\ExptOTCPA_\Pi(\calA) = 1]
%    \]
%    \[
%        \Pr[\calD(\bU) = 1] = 
%        \Pr[\ExptOTCPA_{\Piotp}(\calA) = 1] = \frac{1}{2}
%    \]
%    \begin{align*}
%        \AdvPRG{G}{\calD} 
%        & = \left|\Pr[\calD(G(\bK)) = 1] - \Pr[\calD(\bU) = 1]\right| \\
%        & = \left|\Pr[\ExptOTCPA_\Pi(\calA) = 1]
%           -  \Pr[\ExptOTCPA_{\Piotp}(\calA) = 1]\right| \\
%        & = \left|\Pr[\ExptOTCPA_\Pi(\calA) = 1]
%           -  \frac{1}{2}\right| \\
%        & = \AdvOTCPA{\Pi}{\calA}. 
%    \end{align*}
%
%
%\end{proof}
%
%
%\subsection{Defining Assumptions}
%
%\subsection{Proving Security: Reductions}
%
%\section{Step 1: Encryption Security Definition}
%
%\section{Step 2: Assumption: PRG Security of a Stream Cipher}
%
%\section{Step 3: Security Proof via a Reduction}
%
%In this definition we will need the concept of an \emph{oracle} for an
%algorithm.  You can think about oracles intuitively as ``subroutines'' that an
%algorithm can call. When $\calA$ is an oracle algorithm and $O_1$ is a
%function, we write $\calA^{O_1}$ for $\calA$ connected to the oracle
%(subroutine) $O_1$. If $O_2$ is another oracle, we write $\calA^{O_2}$ for
%$\calA$ connected to $O_2$, and so on. 
%
%A key point in this formalism is that $\calA$ can only observe the input/output
%behavior of its oracle, and \emph{not the code implementing the oracle}.  So if
%$O_1$ and $O_2$ are the same function, then $\calA^{O_1}$ and $\calA^{O_2}$
%will behave exactly the same. 


\end{document}

